# -*- coding: utf-8 -*-
"""home_loans.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VVwB-rgjCyuHv9eE2DowBtdkm6vQZwlP
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

table=pd.read_csv('mortgage.csv')
table



table.info()

table['mat_time'].isnull()

1

table['id'].unique()

table.LTV_time.isnull().sum()

table.dropna()

table=table.dropna()

#table[(table['balance_time']==0)&(table['status_time']!=2),'status_time']=2

table[table['id']==127]

table

table.isnull().sum().sum()

#table=table.groupby('id').last()

#table

#table['balance_time']=table['balance_time']/table['balance_orig_time']

table

bank_df=table.groupby(by='id').last()

bank_df.head()
#bank_df.isnull().sum().sum()

bank_df['duration']=0
bank_df['duration']=table.groupby(by='id').count().iloc[:,0]

bank_df

bank_df['balance_time']=bank_df['balance_time']/bank_df['balance_orig_time']

interv=bank_df['duration']
bank_df.pop('duration')

bank_df.insert(0,'duration',interv)

table.columns

bank_df=bank_df[['duration','time','mat_time','balance_orig_time','LTV_orig_time','REtype_SF_orig_time','REtype_CO_orig_time','uer_time'
                 ,'REtype_PU_orig_time','FICO_orig_time','Interest_Rate_orig_time','hpi_orig_time','default_time','payoff_time',
                 'status_time','LTV_time','balance_time','interest_rate_time','hpi_time','gdp_time']]

bank_df

bank_df.nunique()

default_dist=[bank_df[(bank_df['REtype_CO_orig_time']==1)&(bank_df['default_time']==1)].__len__(),bank_df[(bank_df['REtype_PU_orig_time']==1)&(bank_df['default_time']==1)].__len__(),bank_df[(bank_df['REtype_SF_orig_time']==1)&(bank_df['default_time']==1)].__len__()]
payoff_dist=[bank_df[(bank_df['REtype_CO_orig_time']==1)&(bank_df['payoff_time']==1)].__len__(),bank_df[(bank_df['REtype_PU_orig_time']==1)&(bank_df['payoff_time']==1)].__len__(),bank_df[(bank_df['REtype_SF_orig_time']==1)&(bank_df['payoff_time']==1)].__len__()]
NondefaultNonpayoff_dist=[bank_df[(bank_df['REtype_CO_orig_time']==1)&(bank_df['default_time']==0)&(bank_df['payoff_time']==0)].__len__(),bank_df[(bank_df['REtype_PU_orig_time']==1)&(bank_df['default_time']==0)&(bank_df['payoff_time']==0)].__len__(),bank_df[(bank_df['REtype_SF_orig_time']==1)&(bank_df['default_time']==0)&(bank_df['payoff_time']==0)].__len__()]
default_dist

n=3
r=np.arange(n)
width=0.25
plt.figure(figsize=(10,6))
A=plt.bar(r,default_dist,color='cyan',width=width,edgecolor='white',label='default')
B=plt.bar(r+width,payoff_dist,color='orange',width=width,edgecolor='white',label='paid')
C=plt.bar(r+2*width,NondefaultNonpayoff_dist,color='green',width=width,edgecolor='white',label='default')
plt.xlabel('Real Estate types')
plt.ylabel('Count')
plt.xticks(r+width,['REtype_CO','REtype_PU','REtype_SF'])
plt.legend((A,B,C),('Default','Paid off','Ongoing'))
#plt.grid()
plt.show()

pair_df=bank_df.copy()
pair_df

import seaborn as sns
sns.set(color_codes=True)
sns.color_palette("husl",8)
sns.set(rc={'figure.figsize':(15,10)})
sns.pairplot(pair_df.sample(500).loc[:,['duration','time','mat_time','hpi_orig_time','LTV_orig_time','Interest_Rate_orig_time','status_time']],hue='status_time')

sns.color_palette("hls", 8)
sns.countplot(x='status_time',data=bank_df)

sns.boxplot(x='status_time',y='hpi_orig_time',data=bank_df)

#outlier
bank_df

bank_df.reset_index(inplace=True)
bank_df["status_time_temp"]=10
bank_df.loc[bank_df["status_time"]!=1,"status_time_temp"]="Y"
bank_df.loc[bank_df["status_time"]==1,"status_time_temp"]="N"
bank_df.head()

attri=['balance_orig_time','FICO_orig_time','LTV_orig_time','Interest_Rate_orig_time']
plt.figure(figsize=(18,10))

for ind,col in enumerate(attri):
    sns.set_palette('bright')
    plt.subplot(2,2,ind+1)
    sns.boxplot(data=bank_df,x='status_time_temp',y=col)

col="balance_orig_time"
q1=bank_df[col].quantile(0.25)
q3=bank_df[col].quantile(0.75)
Range=q3-q1
temp_df=bank_df[col]
check=pd.DataFrame(temp_df>q3+1.5*Range)
check[check[col]==True].count()
indexes=[list(check[check[col]==True].index)]
bank_df.drop(bank_df.index[tuple(indexes)],inplace=True)
bank_df.reset_index(inplace=True,drop=False)

bank_df.shape

sns.boxplot(x='status_time_temp',y='balance_orig_time',data=bank_df)

sns.countplot(x='status_time_temp',data=bank_df)

sns.heatmap(bank_df.corr(),cmap='Greens')

!pip install ppscore

dfforpps=bank_df.copy()
dfforpps=dfforpps.drop(['index','id','default_time','payoff_time'],axis=1)
dfforpps.columns

import ppscore as pps
pps_mat=pps.matrix(dfforpps).pivot(columns="x",index="y",values='ppscore')
sns.heatmap(pps_mat,cmap='Greens',annot=True)

import sklearn
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
sc=StandardScaler()
x=sc.fit_transform(dfforpps.drop(['time','status_time','status_time_temp','REtype_PU_orig_time','REtype_CO_orig_time','REtype_SF_orig_time','Interest_Rate_orig_time','hpi_time'],axis=1))
pca=PCA(0.95)
x=pca.fit_transform(x)
var=pca.explained_variance_ratio_
var

x

plt.plot(var)

plt.plot(np.cumsum(var))

x=pd.DataFrame(x)
x['status_time']=bank_df['status_time']
x.loc[x['status_time']!=1,'status_time']=2

x

red_df_x=x.copy()

from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.tree import DecisionTreeClassifier
import pickle
from sklearn import preprocessing

copy_for_y=bank_df.copy()
copy_for_y['status_time_bin']=2
copy_for_y.loc[copy_for_y['status_time']==1,'status_time_bin']=1
y=copy_for_y['status_time_bin']

label_encoder=preprocessing.LabelEncoder()
y_label= label_encoder.fit_transform(y)
y_label
#y_label= label_encoder.fit_transform(y)
#y_label
#label_encoder = preprocessing.LabelEncoder()

# Encode labels in column 'species'.

y_label.shape

orig_x_df=bank_df.drop(['index','id','status_time','status_time_temp','hpi_orig_time','default_time','payoff_time'],axis=1)

orig_x_df.shape

x_train,x_test,y_train,y_test=train_test_split(orig_x_df,y_label,test_size=0.4,random_state=42)

params = {'max_depth':range(3,20),'criterion':['gini','entropy']}
dt_orig_class=GridSearchCV(DecisionTreeClassifier(),params,scoring='roc_auc',cv=5,n_jobs=-1)
dt_orig_class.fit(x_train,y_train)
tree_orig=dt_orig_class.best_estimator_
print(dt_orig_class.best_score_,dt_orig_class.best_params_)

prediction=dt_orig_class.predict(x_train)
accuracy_score(y_train,prediction)

dt_orig_test=DecisionTreeClassifier(**dt_orig_class.best_params_,random_state=42)
dt_orig_test.fit(x_train,y_train)
prediction=dt_orig_test.predict(x_test)
accuracy_score(y_test,prediction)

print(precision_score(y_test,prediction))
print(recall_score(y_test,prediction))
print(f1_score(y_test,prediction))

from sklearn import tree
fig=plt.figure(figsize=(25,20))
tree.plot_tree(dt_orig_test,feature_names=orig_x_df.columns,class_names=['Default','Payoff'],filled=True)
#tree.plot_tree(dt_orig_test)
plt.show()

dt_orig_test.feature_importances_

imp_feat=pd.Series(dt_orig_test.feature_importances_,index=x_train.columns).sort_values(ascending=False)
imp_feat

sns.barplot(x=imp_feat,y=imp_feat.index)

x_train,x_test,y_train,y_test=train_test_split(orig_x_df,y_label,test_size=0.25,random_state=42)

from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

sc=StandardScaler()
sc.fit(x_train)
x_train_sc=sc.transform(x_train)
x_test_sc=sc.transform(x_test)

svc_model=SVC(C=1.0,random_state=42,kernel='rbf',probability=True)
svc_model.fit(x_train_sc,y_train)

y_pred=svc_model.predict(x_test_sc)
print(accuracy_score(y_test,y_pred))
print(precision_score(y_test,y_pred))
print(recall_score(y_test,y_pred))
print(f1_score(y_test,y_pred))

confusion_matrix(y_test,y_pred)

supports=svc_model.support_vectors_
plt.scatter(x_train.iloc[:,0],x_train.iloc[:,1])
plt.scatter(supports[:,0],supports[:,1],color="yellow")

x_train.__len__()

#pd.Series(abs(svc_model.coef_[0]),index=orig_x_df.columns).nlargest(15).plot(kind='barh')

pip install tensorflow --user

pip install keras

x_train,x_test,y_train,y_test=train_test_split(orig_x_df,y_label,test_size=0.25,random_state=42)

sc=StandardScaler()
sc.fit(x_train)
x_train_sc=sc.transform(x_train)
x_test_sc=sc.transform(x_test)

y_ann=pd.get_dummies(y_label)
y_ann

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
#from keras.optimizers import adam
model=Sequential()
model.add(Dense(units=128,activation='relu',input_dim=x_train.shape[1]))
model.add(Dense(units=64,activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(units=20,activation='relu'))
model.add(Dropout(0.1))
model.add(Dense(units=1,activation='sigmoid'))
#opt=adam(learning_rate=0.001)
model.compile(optimizer = 'adam', loss='binary_crossentropy',metrics=['accuracy'])
#model.compile(optimizer = opt, loss='binary_crossentropy',metrics=['accuracy'])
model.fit(x_train_sc,y_train,batch_size=64,epochs=100)
score,accur=model.evaluate(x_train_sc,y_train,batch_size=64)

y_pred=model.predict(x_test_sc)
score,accur=model.evaluate(x_test_sc,y_test,batch_size=64)
print(score)
print(accur)

y_pred_test_round=[int(round(i[0])) for i in y_pred]

accuracy_score(y_test,y_pred_test_round)

y_pred_train=model.predict(x_train_sc)
y_pred_round=[int(round(i[0])) for i in y_pred_train]
accuracy_score(y_train,y_pred_round)

print(precision_score(y_test,y_pred_test_round))
print(recall_score(y_test,y_pred_test_round))
print(f1_score(y_test,y_pred_test_round))

#ROC

x_train,x_test,y_train,y_test=train_test_split(orig_x_df,y_label,test_size=0.25,random_state=42)

from sklearn.metrics import roc_curve,roc_auc_score
models=[dt_orig_test]
outcome=pd.DataFrame(columns=['models','tpr','fpr','auc'])
for mod in models:
    yprob=mod.predict_proba(x_test)[::,1]
    fpr,tpr,waste=roc_curve(y_test,yprob)
    auc=roc_auc_score(y_test,yprob)
    outcome=outcome.append({'models':mod.__class__.__name__,
                            'fpr':fpr,
                            'tpr':tpr,
                            'auc':auc},ignore_index=True)
models=[model]
sc=StandardScaler()
sc.fit(x_train)
x_train_sc=sc.transform(x_train)
x_test_sc=sc.transform(x_test)

for mod in models:
    yprob=mod.predict(x_test_sc)
    fpr,tpr,waste=roc_curve(y_test,yprob)
    auc=roc_auc_score(y_test,yprob)
    outcome=outcome.append({'models':mod.__class__.__name__,
                            'fpr':fpr,
                            'tpr':tpr,
                            'auc':auc},ignore_index=True)
models=[svc_model]
for mod in models:
    yprob=mod.predict_proba(x_test_sc)[::,1]
    fpr,tpr,waste=roc_curve(y_test,yprob)
    auc=roc_auc_score(y_test,yprob)
    outcome=outcome.append({'models':mod.__class__.__name__,
                            'fpr':fpr,
                            'tpr':tpr,
                            'auc':auc},ignore_index=True)
models=[dt_orig_test,model,svc_model]
outcome.set_index('models',inplace=True)

fig=plt.figure(figsize=(10,8))
for i in outcome.index:
    plt.plot(outcome.loc[i]['fpr'],outcome.loc[i]['tpr'],
             label="{}, AUC={:,.3f}".format(i, outcome.loc[i]['auc']))
plt.legend(loc='lower right')

outcome

#Applying models on PCA features
x

#DT
x_train,x_test,y_train,y_test=train_test_split(x.drop(['status_time'],axis=1),y_label,test_size=0.3,random_state=42)

y_train

params={'max_depth':range(3,20),'criterion':['gini','entropy']}
clf=GridSearchCV(DecisionTreeClassifier(),params,cv=5,scoring='roc_auc',n_jobs=-1)
clf.fit(x_train,y_train)
tree_model=clf.best_estimator_
print(clf.best_score_,clf.best_params_)

dt_pca=DecisionTreeClassifier(**clf.best_params_,random_state=42)

dt_pca.fit(x_train,y_train)
pred=dt_pca.predict(x_test)
accuracy_score(y_test,pred)

print(precision_score(y_test,pred))
print(recall_score(y_test,pred))
print(f1_score(y_test,pred))

imp_feat=pd.Series(dt_pca.feature_importances_,index=x_train.columns).sort_values(ascending=False)
imp_feat

sns.barplot(y=imp_feat,x=imp_feat.index)

#SVC
x_train,x_test,y_train,y_test=train_test_split(x.drop(['status_time'],axis=1),y_label,test_size=0.3,random_state=42)

svc_pca=SVC(C=1.0,kernel='linear',probability=True,random_state=42)
svc_pca.fit(x_train,y_train)

y_pred=svc_pca.predict(x_test)
accuracy_score(y_test,y_pred)

print(precision_score(y_test,pred))
print(recall_score(y_test,pred))
print(f1_score(y_test,pred))

supports=svc_pca.support_vectors_
plt.scatter(x_train.iloc[:,0],x_train.iloc[:,1])
plt.scatter(supports[:,0],supports[:,1], color='orange')

pd.Series(abs(svc_pca.coef_[0]),index=x.drop(['status_time'],axis=1).columns).nlargest(20).plot(kind='barh')

x

#ANN
x_train,x_test,y_train,y_test=train_test_split(x.drop(['status_time'],axis=1),y_label,test_size=0.3,random_state=42)

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
#from keras.optimizers import adam
model_pca=Sequential()
model_pca.add(Dense(units=128,activation='relu',input_dim=x_train.shape[1]))
model_pca.add(Dense(units=64,activation='relu'))
model_pca.add(Dropout(0.1))
model_pca.add(Dense(units=20,activation='relu'))
model_pca.add(Dropout(0.1))
model_pca.add(Dense(units=1,activation='sigmoid'))
#opt=adam(learning_rate=0.001)
model_pca.compile(optimizer = 'adam', loss='binary_crossentropy',metrics=['accuracy'])
#model.compile(optimizer = opt, loss='binary_crossentropy',metrics=['accuracy'])
model_pca.fit(x_train,y_train,batch_size=64,epochs=100)
score,accur=model_pca.evaluate(x_train,y_train,batch_size=64)

y_pred=model_pca.predict(x_test)
score, accur = model_pca.evaluate(x_test,y_test,batch_size=64)
print(score)
print(accur)

y_pred_round=[int(round(i[0])) for i in y_pred]
accuracy_score(y_test,y_pred_round)

print(precision_score(y_test,y_pred_round))
print(recall_score(y_test,y_pred_round))
print(f1_score(y_test,y_pred_round))

y_pred_train=model_pca.predict(x_train)
y_round_train=[int(round(i[0])) for i in y_pred_train]
accuracy_score(y_train,y_round_train)

#ROC curves
x_train,x_test,y_train,y_test=train_test_split(x.drop(['status_time'],axis=1),y_label,test_size=0.3,random_state=42)

models=[dt_pca,svc_pca]
outcome_pca=pd.DataFrame(columns=['models','fpr','tpr','auc'])

for mod in models:
    y_prob=mod.predict_proba(x_test)[::,1]
    fpr,tpr,waste=roc_curve(y_test,y_prob)
    auc=roc_auc_score(y_test,y_prob)
    outcome_pca=outcome_pca.append({'models':mod.__class__.__name__,
                                    'fpr':fpr,
                                    'tpr':tpr,
                                    'auc':auc},ignore_index=True)
models=[model_pca]
for mod in models:
    y_prob=mod.predict(x_test)
    fpr,tpr,waste=roc_curve(y_test,y_prob)
    auc=roc_auc_score(y_test,y_prob)
    outcome_pca=outcome_pca.append({'models':mod.__class__.__name__,
                                    'fpr':fpr,
                                    'tpr':tpr,
                                    'auc':auc},ignore_index=True)
models=[dt_pca,svc_pca,model_pca]
outcome_pca.set_index('models',inplace=True)

fig=plt.figure(figsize=(10,8))

for i in outcome_pca.index:
    plt.plot(outcome_pca.loc[i]['fpr'],
             outcome_pca.loc[i]['tpr'],
             label="{}, AUC={:0.3f}".format(i,outcome_pca.loc[i]['auc']))
plt.legend()

